{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "5.0-DL_with_CNN(tf2.0).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vnZnnBjcvGPw"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shinebalance/DL_notes/blob/master/DeepLearningwithPython/5_1_CNN(tf2_0).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E1zkSkiPvGPp",
        "colab_type": "text"
      },
      "source": [
        "# **(TF2.0学習)5.1 CNN**\n",
        "---\n",
        "\n",
        "## 【目的】\n",
        "* 以下書籍,第5章の内容をTF2.0のsubclassingで整理して学習するnotebook  \n",
        "\n",
        "<div align=\"center\">\n",
        "<img src=\"https://book.mynavi.jp/files/topics/90124_ext_06_0.jpg\" frameborder=\"0\" width=\"110\" height=\"125\" scrolling=\"yes\"></img></div>  \n",
        "https://book.mynavi.jp/ec/products/detail/id=90124  \n",
        "\n",
        "## 【お品書き】\n",
        " 1. CNNのしくみ(5.1)  \n",
        "\n",
        "> 今回追加で参考にしたもの  \n",
        "> https://note.nkmk.me/python-tensorflow-keras-basics/  \n",
        "> https://www.atmarkit.co.jp/ait/articles/2002/27/news021.html\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy7Rs4jUvGPq",
        "colab_type": "text"
      },
      "source": [
        "# Kerasのインポート"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0Ocjl9hzBin",
        "colab_type": "code",
        "outputId": "6d6add96-b80c-4e82-becb-135b2627cb72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "# 2.0をColabで実行する際に必要らしい\n",
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDck7fclvGPr",
        "colab_type": "code",
        "outputId": "4b6f8a1a-49cd-46eb-f3d0-e34318a0ca03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "print(tf.__version__)\n",
        "\n",
        "# enable eager execution...2.0が導入できていればDefaultでEnable\n",
        "# tf.enable_eager_execution()\n",
        "print(tf.executing_eagerly())"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQxOTMz1vGPv",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "# 1)CNNのしくみ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnZnnBjcvGPw",
        "colab_type": "text"
      },
      "source": [
        "## MNIST分類を行うシンプルなCNNモデル……を、Functional APIで書くと"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qhs3vjovGPx",
        "colab_type": "code",
        "outputId": "a747a83d-4b04-466a-b877-e5c40efbd540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "source": [
        "inputs = tf.keras.Input(shape=(28, 28, 1))\n",
        "\n",
        "x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "'''\n",
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())#FlattenよりもGlobalAveragePool2D()がいいらしい\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dense(10, activation='softmax'))#分類なので最後はrelu+Softmax\n",
        "'''\n",
        "\n",
        "# モデル形状の確認\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 28, 28, 1)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                36928     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 93,322\n",
            "Trainable params: 93,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YF_H2NM_zgtD",
        "colab_type": "text"
      },
      "source": [
        "## Subclassing APIで実装すると(本命)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRVjMM3AzmHR",
        "colab_type": "code",
        "outputId": "25d7c47e-06ec-4224-dd84-db571f822182",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Subclassing API\n",
        "class SimpleCNN_sc(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN_sc, self).__init__()\n",
        "        self.cn1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')\n",
        "        self.max1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
        "        self.cn2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')\n",
        "        self.max2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
        "        self.cn3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')\n",
        "        self.flatten = tf.keras.layers.Flatten()\n",
        "        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n",
        "        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n",
        "\n",
        "    def call(self, x, training=False):\n",
        "        x = self.cn1(x)\n",
        "        x = self.max1(x)\n",
        "        x = self.cn2(x)\n",
        "        x = self.max2(x)\n",
        "        x = self.cn3(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.dense1(x)\n",
        "        x = self.dense2(x)\n",
        "        return x\n",
        "\n",
        "model = SimpleCNN_sc()\n",
        "model.build((None, 28, 28, 1))\n",
        "\n",
        "'''\n",
        "inputs = tf.keras.Input(shape=(28, 28, 1))\n",
        "\n",
        "x = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "'''\n",
        "\n",
        "# モデル形状の確認\n",
        "## Output shapeは表示されない\n",
        "# model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ninputs = tf.keras.Input(shape=(28, 28, 1))\\n\\nx = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\\nx = tf.keras.layers.MaxPooling2D((2, 2))(x)\\nx = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\\nx = tf.keras.layers.MaxPooling2D((2, 2))(x)\\nx = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(x)\\nx = tf.keras.layers.Flatten()(x)\\nx = tf.keras.layers.Dense(64, activation='relu')(x)\\noutputs = tf.keras.layers.Dense(10, activation='softmax')(x)\\n\\nmodel = tf.keras.Model(inputs=inputs, outputs=outputs)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vyHvB5CvGPz",
        "colab_type": "text"
      },
      "source": [
        "## 前処理を実施してモデルの訓練を実施……を、model.fit()ではなく自力で回す"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YyoPZ5RPwG4",
        "colab_type": "text"
      },
      "source": [
        "> memo  \n",
        "> tutorialだとone-hot encoding せずにsparse categorical entropyを使ってる  \n",
        "> https://www.tensorflow.org/tutorials/quickstart/advanced?hl=ja"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guuDQrrL2F5K",
        "colab_type": "text"
      },
      "source": [
        "### 試行1: metric:Accuracy\n",
        "* 元ネタのKeras実装を文言通りに実行した結果"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aNZrltG7fmu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# 28*28に成形して正規化\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "# カテゴリ値に変更\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "'''\n",
        "# all keras ver\n",
        "# オプティマイザ, 損失関数, メトリックを決めて学習実行\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
        "'''\n",
        "\n",
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.01)\n",
        "# loss function\n",
        "loss_fn = tf.keras.losses.categorical_crossentropy\n",
        "# metric... need ()\n",
        "metrics_acc = tf.keras.metrics.Accuracy()\n",
        "# metrics_acc = tf.keras.metrics.CategoricalCrossentropy()\n",
        "\n",
        "# set status\n",
        "epochs = 5\n",
        "batch_size = 64\n",
        "'''\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)\n",
        "'''\n",
        "# tf.Data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_dataset = test_dataset.batch(64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHWfZzL2OkeX",
        "colab_type": "code",
        "outputId": "1f9a67e7-a3fc-49ce-ef71-e4ce366b504e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "print(train_images.shape)\n",
        "print(train_images.dtype)\n",
        "print(train_labels.dtype)\n",
        "print(train_labels.shape)\n",
        "# one-hot encodingされていることを確認"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "float32\n",
            "float32\n",
            "(60000, 10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhILLHb-vGP0",
        "colab_type": "code",
        "outputId": "f86d3f60-8c9f-4213-d1b4-e9b1b6988a97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        }
      },
      "source": [
        "# Iterate\n",
        "for epoch in range(epochs):\n",
        "  print('Start of epoch %d' % (epoch+1,))\n",
        "\n",
        "  # Inside epoch(per batch size)\n",
        "  for step, (train_images, train_labels) in enumerate(train_dataset):\n",
        "    with tf.GradientTape() as tape:\n",
        "      _y = model(train_images)\n",
        "      # loss\n",
        "      loss = loss_fn(train_labels, _y)\n",
        "      loss += sum(model.losses)  # pile up loss\n",
        "\n",
        "    # compute grads\n",
        "    grads = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    #print(train_labels[step])\n",
        "    #print(_y[step])\n",
        "    metrics_acc(train_labels, _y)\n",
        "\n",
        "    if step % 512 == 0:\n",
        "      #print('step %s: mean loss = %s' % (step, metrics_acc.result()))\n",
        "      template = 'Step {}, metrics_acc: {} %'\n",
        "      print(template.format(step, metrics_acc.result() * 100))\n",
        "    \n",
        "    metrics_acc.reset_states()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of epoch 1\n",
            "Step 0, metrics_acc: 0.78125 %\n",
            "Step 512, metrics_acc: 82.5 %\n",
            "Start of epoch 2\n",
            "Step 0, metrics_acc: 81.875 %\n",
            "Step 512, metrics_acc: 83.125 %\n",
            "Start of epoch 3\n",
            "Step 0, metrics_acc: 83.125 %\n",
            "Step 512, metrics_acc: 82.1875 %\n",
            "Start of epoch 4\n",
            "Step 0, metrics_acc: 82.1875 %\n",
            "Step 512, metrics_acc: 82.1875 %\n",
            "Start of epoch 5\n",
            "Step 0, metrics_acc: 82.1875 %\n",
            "Step 512, metrics_acc: 83.4375 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbu67FrevGP2",
        "colab_type": "text"
      },
      "source": [
        "#### 検証データの精度を確認"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jb4LP9iVvGP3",
        "colab_type": "code",
        "outputId": "db915b08-a838-4105-f2ed-c03bdc79e715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "test_metrics_acc = tf.keras.metrics.Accuracy()\n",
        "\n",
        "# Run a validation loop at the end of each epoch.\n",
        "for test_images, test_labels in test_dataset:\n",
        "  _y_pred = model(test_images)\n",
        "  test_metrics_acc(test_labels, _y_pred)\n",
        "\n",
        "val_acc = test_metrics_acc.result()\n",
        "test_metrics_acc.reset_states()\n",
        "print('Validation acc: %s' % (float(val_acc),))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation acc: 0.822700023651123\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6k761LZvGP5",
        "colab_type": "text"
      },
      "source": [
        "> While our densely-connected network from Chapter 2 had a test accuracy of 97.8%, our basic convnet has a test accuracy of 99.3%: we decreased our error rate by 68% (relative). Not bad! \n",
        "\n",
        "全結合器が97.8%なので、その値超える結果なら上々だね！ by Francois"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCerlA364q_U",
        "colab_type": "text"
      },
      "source": [
        "精度が落ちている？？？"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUb3VSgJ20m5",
        "colab_type": "text"
      },
      "source": [
        "### 試行2: metric:metrics.SparseCategoricalAccuracy\n",
        "* 公式チュートリアルの組み合わせをやってみる"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQX-2ozvFrs9",
        "colab_type": "code",
        "outputId": "cb0f695c-e30c-413c-e0e6-272640568d9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        }
      },
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# 28*28に成形して正規化\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255.0\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255.0\n",
        "\n",
        "\n",
        "# カテゴリ値に変更…を行わない\n",
        "# train_labels = to_categorical(train_labels)\n",
        "# test_labels = to_categorical(test_labels)\n",
        "\n",
        "# float32化しておく\n",
        "# train_labels = train_labels.astype('float32')\n",
        "# test_labels  = test_labels.astype('float32')\n",
        "\n",
        "# Optimizer\n",
        "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.001)\n",
        "# loss function...SparseCategoricalCrossentropy need()\n",
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "# metric...Accuracy()>>> need ()\n",
        "metrics_acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "# set status\n",
        "epochs = 5\n",
        "batch_size = 64\n",
        "'''\n",
        "print(train_images.shape)\n",
        "print(test_images.shape)\n",
        "'''\n",
        "# tf.Data\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
        "test_dataset = test_dataset.batch(64)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXT_Rv9O9p8O",
        "colab_type": "code",
        "outputId": "9da70579-9b9e-4d99-e13d-c9e25ad12a94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "print(train_images.shape)\n",
        "print(train_images.dtype)\n",
        "print(train_labels.dtype)\n",
        "print(train_labels.shape)\n",
        "# one-hot encodingされていないことを確認"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28, 1)\n",
            "float32\n",
            "uint8\n",
            "(60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NB5enmOP91z2",
        "colab_type": "code",
        "outputId": "7db00b4d-666f-4948-ea7b-a428c8088b20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "# timestamp\n",
        "import time\n",
        "\n",
        "# Iterate\n",
        "for epoch in range(epochs):\n",
        "  print('Start of epoch %d' % (epoch+1,))\n",
        "  _start = time.time()\n",
        "\n",
        "  # Inside epoch(per batch size)\n",
        "  for step, (train_images, train_labels) in enumerate(train_dataset):\n",
        "    with tf.GradientTape() as tape:\n",
        "      _y = model(train_images)\n",
        "      # loss\n",
        "      loss = loss_fn(train_labels, _y)\n",
        "      loss += sum(model.losses)  # pile up loss\n",
        "\n",
        "    # compute grads\n",
        "    grads = tape.gradient(loss, model.trainable_weights)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "    metrics_acc(train_labels, _y)\n",
        "\n",
        "    if step % 512 == 0:\n",
        "      #print('step %s: mean loss = %s' % (step, metrics_acc.result()))\n",
        "      template = 'Step {}, metrics_acc: {} %'\n",
        "      print(template.format(step, metrics_acc.result() * 100))\n",
        "    \n",
        "    metrics_acc.reset_states()\n",
        "\n",
        "_end = time.time() - _start\n",
        "print(\"secs:\", _end)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of epoch 1\n",
            "Step 0, metrics_acc: 98.4375 %\n",
            "Step 512, metrics_acc: 100.0 %\n",
            "Start of epoch 2\n",
            "Step 0, metrics_acc: 100.0 %\n",
            "Step 512, metrics_acc: 100.0 %\n",
            "Start of epoch 3\n",
            "Step 0, metrics_acc: 100.0 %\n",
            "Step 512, metrics_acc: 100.0 %\n",
            "Start of epoch 4\n",
            "Step 0, metrics_acc: 100.0 %\n",
            "Step 512, metrics_acc: 100.0 %\n",
            "Start of epoch 5\n",
            "Step 0, metrics_acc: 100.0 %\n",
            "Step 512, metrics_acc: 100.0 %\n",
            "secs: 16.93676447868347\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5G7SqZ_LZQz",
        "colab_type": "text"
      },
      "source": [
        "#### 検証"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38T1MGJ2N_0e",
        "colab_type": "code",
        "outputId": "862cdbc1-e749-44c3-842e-ee7b68b9686c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "test_metrics_acc = tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "# Run a validation loop at the end of each epoch.\n",
        "for test_images, test_labels in test_dataset:\n",
        "  _start = time.time()\n",
        "  _y_pred = model(test_images)\n",
        "  test_metrics_acc(test_labels, _y_pred)\n",
        "\n",
        "val_acc = test_metrics_acc.result()\n",
        "test_metrics_acc.reset_states()\n",
        "print('Validation acc: %s' % (float(val_acc),))\n",
        "\n",
        "_end = time.time() - _start\n",
        "print(\"secs:\", _end)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation acc: 0.9918000102043152\n",
            "secs: 0.005369424819946289\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkP2HggN1H4R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXd3mXQgKddf",
        "colab_type": "text"
      },
      "source": [
        "### 試行3:@tf.functionを用いた高速化を試す"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IHHl9MW7KVx-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "outputId": "f013210d-3796-43b4-864b-c2625f8f6cff"
      },
      "source": [
        "# timestamp\n",
        "import time\n",
        "\n",
        "# fill train cycle in def\n",
        "@tf.function\n",
        "def train_cycle(train_image, train_labels):\n",
        "  with tf.GradientTape() as tape:\n",
        "    _y = model(train_images)\n",
        "    loss = loss_fn(train_labels, _y)\n",
        "    loss += sum(model.losses)  # pile up loss\n",
        "  # compute grads\n",
        "  grads = tape.gradient(loss, model.trainable_weights)\n",
        "  optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "  metrics_acc(train_labels, _y)\n",
        "\n",
        "\n",
        "# Iterate\n",
        "for epoch in range(epochs):\n",
        "  print('Start of epoch %d' % (epoch+1,))\n",
        "  _start = time.time()\n",
        "\n",
        "  # Inside epoch(per batch size)\n",
        "  for step, (train_images, train_labels) in enumerate(train_dataset):\n",
        "    train_cycle(train_images, train_labels)\n",
        "\n",
        "    if step % 512 == 0:\n",
        "      #print('step %s: mean loss = %s' % (step, metrics_acc.result()))\n",
        "      template = 'Step {}, metrics_acc: {} %'\n",
        "      print(template.format(step, metrics_acc.result() * 100))\n",
        "    \n",
        "    metrics_acc.reset_states()\n",
        "\n",
        "_end = time.time() - _start\n",
        "print(\"secs:\", _end)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of epoch 1\n",
            "ERROR! Session/line number was not unique in database. History logging moved to new session 65\n",
            "Step 0, metrics_acc: 10.9375 %\n",
            "Step 512, metrics_acc: 12.5 %\n",
            "Start of epoch 2\n",
            "Step 0, metrics_acc: 6.25 %\n",
            "Step 512, metrics_acc: 14.0625 %\n",
            "Start of epoch 3\n",
            "Step 0, metrics_acc: 12.5 %\n",
            "Step 512, metrics_acc: 7.8125 %\n",
            "Start of epoch 4\n",
            "Step 0, metrics_acc: 9.375 %\n",
            "Step 512, metrics_acc: 10.9375 %\n",
            "Start of epoch 5\n",
            "Step 0, metrics_acc: 17.1875 %\n",
            "Step 512, metrics_acc: 9.375 %\n",
            "secs: 3.372530698776245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ifpEZw0QRGc",
        "colab_type": "text"
      },
      "source": [
        "精度は異様に落ちたが速度は段違いに早い"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1QI3dNavGP7",
        "colab_type": "text"
      },
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "  \n",
        "---\n",
        "\n",
        "編集前のnoteではこのあと5.2 ,3 ,4を1つのnoteにまとめていたが、上記の通り内容が増えたため別のnoteでtf2.0化を行う  \n",
        "<br>\n",
        "\n",
        "**EOF**"
      ]
    }
  ]
}